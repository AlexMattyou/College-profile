## Question Set:

1. Build a DNN to classify the IRIS dataset. Use activation functions of your
choice and evaluate the model’s accuracy. (50)

2. Implement a DNN for solving a multi-class classification problem on the MNIST
dataset. (50)

3. Compare the performance of shallow vs deep neural networks for a binary
classification problem.(50)

4. Train a CNN for classifying dogs vs cats using a subset of the Kaggle dataset.
(50)

5. Use transfer learning with a pre-trained CNN model (e.g., VGG16) to improve
face recognition accuracy. (50)

6. Implement a CNN to detect specific objects in an image and visualize feature
maps at each layer. (50)

7. Train an RNN-based text generator to produce text in the style of
Shakespeare. (50)

8. Implement a time-series forecasting model using RNN on stock market or
weather data. (50)

9. Compare the performance of a simple RNN with an LSTM for sequence
prediction tasks.(50)

10.Build an LSTM-based spam classifier using email or SMS datasets.(50)

11. Train an LSTM for anomaly detection in network traffic or IoT device logs.(50)

12. Use bidirectional LSTMs for sentiment analysis on the Amazon review
dataset.(50)

13. Implement a chatbot using a Seq2Seq model trained on movie dialogues
(Cornell dataset).(50)

14. Design a spell-corrector using a Seq2Seq model that maps incorrect words to
their correct counterparts.(50)

15. Use a Seq2Seq model for text summarization on news articles.(50)

16. Train an encoder-decoder model with attention for summarizing legal
documents.(50)

17. Implement an encoder-decoder model to convert Roman numerals into Arabic
numerals. (50)

18. Compare the performance of encoder-decoder models with and without
attention mechanisms for machine translation. (50)

19. Implement a CycleGAN to translate images between two domains (e.g.,
summer to winter landscapes). (50)

20. Use a GAN to generate synthetic faces and evaluate them using the Fréchet
Inception Distance (FID).(50)

21. Develop a GAN-based data augmentation pipeline and apply it to improve the
performance of a CNN classifier. (50)

22. Design a deep neural network (DNN) with at least one hidden layer to solve
the XOR problem. Use sigmoid activation functions and backpropagation for
training.(50)

23. Implement a convolutional neural network (CNN) for recognizing handwritten
characters from a dataset such as EMNIST.(50)

24. Build a CNN-based face recognition system using datasets like LFW (Labeled
Faces in the Wild). (50)

25. Develop a Recurrent Neural Network (RNN)-based language model to predict
the next word in a sentence. (50)

26. Build an LSTM-based model to perform sentiment analysis on a dataset like
IMDB or Twitter Sentiment Analysis. (50)

27. Implement an encoder-decoder model for English-to-French translation using
datasets like the TED Talks multilingual corpus. (50)